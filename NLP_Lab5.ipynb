{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loics21/COS470---NLP/blob/main/NLP_Lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Lab 5\n",
        "### Computer Engineering StackExchange vs. ChatGPT"
      ],
      "metadata": {
        "id": "Aca7fba2HA97"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjPSivFkHI09"
      },
      "outputs": [],
      "source": [
        "from post_parser_record import PostParserRecord\n",
        "from collections import Counter\n",
        "\n",
        "## Getting the top-20 frequent tags in LawSE -- There is a reason for passing 21\n",
        "def get_frequent_tags(post_parser, topk=21):\n",
        "  lst_tags = []\n",
        "  for question_id in post_parser.map_questions:\n",
        "    question = post_parser.map_questions[question_id]\n",
        "    creation_date_year = int(question.creation_date.split(\"-\")[0])\n",
        "    tag = question.tags[0]\n",
        "    lst_tags.append(tag)\n",
        "  tag_freq_dic = dict(Counter(lst_tags))\n",
        "  tag_freq_dic = dict(sorted(tag_freq_dic.items(), key=lambda item: item[1], reverse=True))\n",
        "  return list(tag_freq_dic.keys())[:topk]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting dictionary of train and test samples in form of\n",
        "# key: tag value: list of tuples in form of (title, body)\n",
        "def build_train_test(post_parser, lst_frequent_tags):\n",
        "  dic_training = {}\n",
        "  dic_test = {}\n",
        "  for question_id in post_parser.map_questions:\n",
        "    question = post_parser.map_questions[question_id]\n",
        "    creation_date_year = int(question.creation_date.split(\"-\")[0])\n",
        "    tag = question.tags[0]\n",
        "    if tag in lst_frequent_tags:\n",
        "      title = question.title\n",
        "      body = question.body\n",
        "      if creation_date_year > 2021:\n",
        "        if tag in dic_test:\n",
        "          dic_test[tag].append((title, body))\n",
        "        else:\n",
        "          dic_test[tag] = [(title, body)]\n",
        "      else:\n",
        "        if tag in dic_training:\n",
        "          dic_training[tag].append((title, body))\n",
        "        else:\n",
        "          dic_training[tag] = [(title, body)]\n",
        "  return dic_test, dic_training"
      ],
      "metadata": {
        "id": "IUb9nbM8K9Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_parser = PostParserRecord(\"Posts_law.xml\")\n",
        "lst_frequent_tags = get_frequent_tags(post_parser)\n",
        "# We removed contract as it had no post after 2021\n",
        "lst_frequent_tags.remove(\"contract\")\n",
        "dic_test, dic_training = build_train_test(post_parser, lst_frequent_tags)\n",
        "print(\"class\\t#training\\t#test\")\n",
        "for item in dic_training:\n",
        "  print(str(item) + \"\\t\" +str(len(dic_training[item]))+\"\\t\"+str(len(dic_test[item])))"
      ],
      "metadata": {
        "id": "JdQEEfJkL1YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Esr_97yFG9Yt"
      },
      "outputs": [],
      "source": []
    }
  ]
}